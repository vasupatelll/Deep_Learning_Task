{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PT_-eL5YN6u2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aYiKRq_NO5M8"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "print(train_labels[0])\n",
    "plt.imshow(train_images[0])\n",
    "plt.show()\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_images.astype(np.float32) / 255, train_labels.reshape(-1).astype(np.int32)))\n",
    "train_data = train_data.shuffle(buffer_size=60000).batch(128).repeat()\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (test_images.astype(np.float32) / 255, test_labels.reshape(-1).astype(np.int32))).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydaUWqbRPeqM"
   },
   "outputs": [],
   "source": [
    "# example: two (basic) inception blocks\n",
    "# TODO: add 1x1 convs ;)\n",
    "inputs = tf.keras.layers.Input((32, 32, 3))\n",
    "\n",
    "\n",
    "conv1_1 = tf.keras.layers.Conv2D(32, 1, activation=tf.nn.relu, padding=\"same\",\n",
    "                                 name=\"conv1_1x1\")(inputs)\n",
    "conv1_3 = tf.keras.layers.Conv2D(32, 3, activation=tf.nn.relu, padding=\"same\",\n",
    "                                 name=\"conv1_3x3\")(inputs)\n",
    "conv1_5 = tf.keras.layers.Conv2D(32, 5, activation=tf.nn.relu, padding=\"same\",\n",
    "                                 name=\"conv1_5x5\")(inputs)\n",
    "pool1 = tf.keras.layers.MaxPool2D(3, 1, padding=\"same\", name=\"pool1\")(inputs)\n",
    "\n",
    "concat1 = tf.keras.layers.concatenate([conv1_1, conv1_3, conv1_5, pool1])\n",
    "downscale1 = tf.keras.layers.MaxPool2D(2, padding=\"same\", name=\"downscale1\")(concat1)\n",
    "\n",
    "\n",
    "conv2_1 = tf.keras.layers.Conv2D(64, 1, activation=tf.nn.relu, padding=\"same\",\n",
    "                                 name=\"conv2_1x1\")(downscale1)\n",
    "conv2_3 = tf.keras.layers.Conv2D(64, 3, activation=tf.nn.relu, padding=\"same\",\n",
    "                                 name=\"conv2_3x3\")(downscale1)\n",
    "conv2_5 = tf.keras.layers.Conv2D(64, 5, activation=tf.nn.relu, padding=\"same\",\n",
    "                                 name=\"conv2_5x5\")(downscale1)\n",
    "pool2 = tf.keras.layers.MaxPool2D(3, 1, padding=\"same\", name=\"pool2\")(downscale1)\n",
    "\n",
    "concat2 = tf.keras.layers.concatenate([conv2_1, conv2_3, conv2_5, pool2])\n",
    "downscale2 = tf.keras.layers.MaxPool2D(2, padding=\"same\", name=\"downscale2\")(concat2)\n",
    "\n",
    "flat = tf.keras.layers.Flatten()(downscale2)\n",
    "out = tf.keras.layers.Dense(10)(flat)\n",
    "\n",
    "model = tf.keras.Model(inputs, out, name=\"inception\")\n",
    "\n",
    "\n",
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "accuracy_metric = tf.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# note that functional models are built immediately, assuming we are giving\n",
    "# an input shape\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sI-63rfoHHXZ"
   },
   "outputs": [],
   "source": [
    "# basic training loops can be done like this\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[accuracy_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tE970emYHWNj"
   },
   "outputs": [],
   "source": [
    "# we could also NOT repeat the train_data set, then one epoch = one pass over the full dataset\n",
    "# fit has many other arguments and we can also pass \"callbacks\" that do other stuff besides training\n",
    "model.fit(train_data, steps_per_epoch=1000, epochs=2, validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgDgHCyMH4yD"
   },
   "outputs": [],
   "source": [
    "# evaluate test loss and metrics\n",
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-3HfTCDL-1t"
   },
   "outputs": [],
   "source": [
    "# \"predict\" on new input (i.e. give model outputs)\n",
    "logits_on_test_set = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMpZyyTVmUkW"
   },
   "outputs": [],
   "source": [
    "logits_on_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqIPQOG1NlYL"
   },
   "outputs": [],
   "source": [
    "# another example: a residual block\n",
    "inputs = tf.keras.layers.Input((32, 32, 3))\n",
    "\n",
    "initial_conv = tf.keras.layers.Conv2D(32, 5, activation=tf.nn.relu, padding=\"same\")(inputs)\n",
    "\n",
    "conv1_1 = tf.keras.layers.Conv2D(32, 5, activation=tf.nn.relu, padding=\"same\")(initial_conv)\n",
    "conv1_2 = tf.keras.layers.Conv2D(32, 5, padding=\"same\")(conv1_1)\n",
    "\n",
    "out1 = tf.nn.relu(conv1_2 + initial_conv)\n",
    "\n",
    "# another one?\n",
    "# problem: input and output need to have the same size\n",
    "# so we can neither pool nor change the number of filters\n",
    "# if we want do that, we have to add a transformation to the residual (e.g. 1x1 conv)\n",
    "conv2_1 = tf.keras.layers.Conv2D(32, 5, activation=tf.nn.relu, padding=\"same\")(out1)\n",
    "conv2_2 = tf.keras.layers.Conv2D(32, 5, padding=\"same\")(conv2_1)\n",
    "\n",
    "out2 = tf.nn.relu(conv2_2 + out1)\n",
    "\n",
    "\n",
    "# here's an example of that transformation\n",
    "conv3_1 = tf.keras.layers.Conv2D(64, 5, strides=2, activation=tf.nn.relu, padding=\"same\")(out2)\n",
    "conv3_2 = tf.keras.layers.Conv2D(64, 5, padding=\"same\")(conv3_1)\n",
    "\n",
    "shortcut_transform = tf.keras.layers.Conv2D(64, 1, strides=2)(out2)\n",
    "out3 = tf.nn.relu(conv3_2 + shortcut_transform)\n",
    "\n",
    "\n",
    "flat = tf.keras.layers.Flatten()(out3)\n",
    "logits = tf.keras.layers.Dense(10)(flat)\n",
    "\n",
    "model = tf.keras.Model(inputs, logits)\n",
    "\n",
    "\n",
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "train_acc_metric = tf.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# NOTE!!\n",
    "# writing a model like this is not a great idea as the variable names become\n",
    "# very confusing and it's easy to make mistakes.\n",
    "# better to wrap a residual block into a function, e.g. like this\n",
    "def residual_block(inputs, filters):\n",
    "    conv1 = tf.keras.layers.Conv2D(filters, 5, activation=tf.nn.relu, padding=\"same\")(inputs)\n",
    "    conv2 = tf.keras.layers.Conv2D(filters, 5, padding=\"same\")(conv1)\n",
    "\n",
    "    return tf.nn.relu(conv2 + inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nj1XXIVc8-2T"
   },
   "outputs": [],
   "source": [
    "# stereotypical train-step-with-function-annotation\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(images)\n",
    "        xent = loss_fn(labels, logits)\n",
    "\n",
    "    variables = model.trainable_variables\n",
    "    gradients = tape.gradient(xent, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return xent, logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTvyCwZrQkcw"
   },
   "outputs": [],
   "source": [
    "train_steps = 2000\n",
    "\n",
    "start = time.time()\n",
    "for step, (img_batch, lbl_batch) in enumerate(train_data):\n",
    "    if step > train_steps:\n",
    "        break\n",
    "\n",
    "    xent, logits = train_step(img_batch, lbl_batch)\n",
    "\n",
    "    if not step % 100:\n",
    "        train_acc_metric(lbl_batch, logits)\n",
    "        acc = train_acc_metric.result()\n",
    "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n",
    "        train_acc_metric.reset_states()\n",
    "\n",
    "        stop = time.time()\n",
    "        print(\"took {} seconds\\n\".format(stop-start))\n",
    "        start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkhhvGObTPCD"
   },
   "outputs": [],
   "source": [
    "test_acc_metric = tf.metrics.SparseCategoricalAccuracy()\n",
    "for img_batch, lbl_batch in test_data:\n",
    "    test_acc_metric(lbl_batch, model(img_batch))\n",
    "\n",
    "test_acc_metric.result()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "function_al.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
